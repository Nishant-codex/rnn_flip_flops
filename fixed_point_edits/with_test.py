# -*- coding: utf-8 -*-
"""flip_flop_lstm_states

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V9SlynnIlbvdAEHV1-D28mH45Z1c6D37
"""
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import numpy as np
import os
import absl
import tensorflow as tf
from tensorflow.python.ops import parallel_for as pfor

# from FlipFlop import FlipFlop
from FixedPointSearch import *
from FixedPointStore import *
# import horovod.tensorflow as hvd
# %tensorflow_version 1.x magic
import matplotlib.pyplot as plt
import numpy.random as nrand
import pickle
np.random.seed(400)
# from plot_utils import plot_fps
# import numpy as np
import time
from AdaptiveGradNormClip import AdaptiveGradNormClip
from AdaptiveLearningRate import AdaptiveLearningRate

# if(tf.enable_eager_execution()):
#   print('true')

def build_test_rnn(n_hidden, n_inputs, session):
    '''Build a "vanilla" RNNCell and deterministically set its weights. The
    RNN's fixed points are thus also deterministic, allowing ground truth
    values to be compared against those found by FixedPointFinder.
    Args:
        n_hidden:
            Non-negative int specifying the number of hidden units in the RNN.
        n_inputs:
            Non-negative int specifying the number of inputs to the RNN.
            Inputs are ignored by these test RNN's, so this value can be set
            arbitraily without affecting results. This is included only to
            ensure input dimensionality is consistent across the various objects used in a test.
        session:
            A Tensorflow session within which to initialize the RNNCell.
    '''
    rnn_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)
    # rnn_cell = tf.nn.rnn_cell.GRUCell(n_hidden)
    # rnn_cell = tf.nn.rnn_cell.LSTMCell(n_hidden)

    # These will stay as 0's
    W_np_input = np.zeros([n_inputs, n_hidden], dtype=np.float32)
    b_np = np.zeros([n_hidden], dtype=np.float32)

    # This will be set deterministically
    W_np_state = np.zeros([n_hidden, n_hidden], dtype=np.float32)

    '''The following was chosen to such that resulting networks have some non-
    origin fixed points.'''
    row_vals = np.linspace(-1, 1, n_hidden)
    for in_idx in range(n_hidden):
        W_np_state[in_idx, :] = -np.roll(row_vals, -in_idx)
    # print('\nW=' + str(W_np_state))

    W_np = np.concatenate((W_np_input, W_np_state), axis=0)

    input_data = tf.Variable(np.zeros([1, n_inputs]), dtype=tf.float32)
    state = tf.Variable(np.zeros([1, n_hidden]), dtype=tf.float32)

    output, final_state = rnn_cell(input_data, state)
    W_tf, b_tf = rnn_cell.variables

    assign_W = tf.assign(W_tf, W_np)
    assign_b = tf.assign(b_tf, b_np)

    session.run(tf.global_variables_initializer())
    session.run([assign_W, assign_b])

    return rnn_cell

def generate_initial_states_and_inputs(n_hidden, n_inputs,
                                       n_inits_per_state_dim=3,
                                       min_val_per_state_dim=-1.0,
                                       max_val_per_state_dim=1.0,
                                       debug=False):
    '''Generates a grid of initial states and zeroed-out inputs in a format
    compatible with RNNCell.
    Args:
        n_hidden:
            Non-negative int specifying the number of hidden units in the RNN.
        n_inputs:
            Non-negative int specifying the number of inputs to the RNN.
            Inputs are ignored by these test RNN's, so this value can be set
            arbitraily without affecting results. This is included only to
            ensure input dimensionality is consistent across the various
            objects used in a test.
        n_inits_per_state_dim (optional):
            Non-negative int specifying the grid resolution for each
            dimension. The total number of grid states will be
            pow(n_inits_per_state_dim, n_hidden). Default: 3.
        min_val_per_state_dim (optional):
            Float specifying the minimum value for each state dimension.
            Default: -1.0.
        max_val_per_state_dim (optional):
            Float specifying the maximum value for each state dimension.
            Default: 1.0.
        debug (optional):
            Bool indicating whether to visualize the grid of states for the
            first two state dimensions (first two hidden units). Default:
            False.
    Returns:
        grid_states:
            [n, n_hidden] numpy array with grid_states[i, :] representing one
            initial state.
        inputs:
            [1, n_inputs] numpy array of zeros.
    '''

    # All inputs are set to zero.
    inputs = np.zeros([1,n_inputs])

    grid_coords_1D = (np.linspace(min_val_per_state_dim, max_val_per_state_dim, n_inits_per_state_dim) for hidden_idx in range(n_hidden))
    grid_states_list = np.meshgrid(*grid_coords_1D)

    n_inits = pow(n_inits_per_state_dim, n_hidden)
    grid_states = np.transpose(
        np.reshape(np.array(grid_states_list), [n_hidden, n_inits]))

    # Visualize the grid of initial states (first 2 dims only)
    if debug and n_hidden > 1:
        import matplotlib.pyplot as plt
        plt.figure()
        for state_idx in range(n_inits):
            plt.plot(grid_states[state_idx, 0],
                     grid_states[state_idx, 1],
                     'rx')
        plt.show()

    return grid_states, inputs

def get_ground_truth_path(test_path, n_hidden):
    '''Returns the path of the file containing the ground truth FixedPoints.
    Args:
        test_path:
            String indicating the path of the directory containing all ground
            truth files.
        n_hidden:
            Number of hidden units in the test RNN for which ground truth
            FixedPoints are sought.
    Returns:
        String containing the path to the file containing the ground truth
        FixedPoints.
    '''
    return test_path + str('n_hidden=%02d.fps' % n_hidden)

import pdb 

class FixedPoints(object):
    '''
    A class for storing fixed points and associated data.
    '''

    # List of class attributes
    # All of these refer to Numpy arrays with axis 0 as the batch dimension.
    # Thus, each is concatenatable using np.concatenate(..., axis=0).
    _data_attrs = [
            'xstar',
            'x_init',
            'inputs',
            'F_xstar',
            'qstar',
            'dq',
            'n_iters',
            'J_xstar',
            'eigval_J_xstar',
            'eigvec_J_xstar'
            ]

    def __init__(self,
                 xstar=None,
                 x_init=None,
                 inputs=None,
                 F_xstar=None,
                 qstar=None,
                 dq=None,
                 n_iters=None,
                 J_xstar=None,
                 eigval_J_xstar=None,
                 eigvec_J_xstar=None,
                 do_alloc_nan=False,
                 n=None,
                 n_states=None,
                 n_inputs=None,
                 tol_unique=1e-3,
                 dtype=np.float32,
                 verbose=False):

        self.tol_unique = tol_unique
        self.dtype = dtype
        self.verbose = verbose

        if do_alloc_nan:
            if n is None:
                raise ValueError('n must be provided if '
                                 'do_alloc_nan == True.')
            if n_states is None:
                raise ValueError('n_states must be provided if '
                                 'do_alloc_nan == True.')
            if n_inputs is None:
                raise ValueError('n_inputs must be provided if '
                                 'do_alloc_nan == True.')

            self.n = n
            self.n_states = n_states
            self.n_inputs = n_inputs

            self.xstar = self._alloc_nan((n, n_states))
            self.x_init = self._alloc_nan((n, n_states))
            self.inputs = self._alloc_nan((n, n_inputs))
            self.F_xstar = self._alloc_nan((n, n_states))
            self.qstar = self._alloc_nan((n))
            self.dq = self._alloc_nan((n))
            self.n_iters = self._alloc_nan((n))
            self.J_xstar = self._alloc_nan((n, n_states, n_states))

            self.eigval_J_xstar = self._alloc_nan((n, n_states))
            self.eigvec_J_xstar = self._alloc_nan((n, n_states, n_states))
            self.has_decomposed_jacobians = False

        else:
            if xstar is not None:
                self.n, self.n_states = xstar.shape
            elif x_init is not None:
                self.n, self.n_states = x_init.shape
            elif F_xstar is not None:
                self.n, self.n_states = F_xstar.shape
            elif J_xstar is not None:
                self.n, self.n_states, _ = J_xstar.shape
            else:
                self.n = None
                self.n_states = None

            if inputs is not None:
                self.n_inputs = inputs.shape[1]
                if self.n is None:
                    self.n = inputs.shape[0]
            else:
                self.n_inputs = None

            self.xstar = xstar
            self.x_init = x_init
            self.inputs = inputs
            self.F_xstar = F_xstar
            self.qstar = qstar
            self.dq = dq
            self.n_iters = n_iters
            self.J_xstar = J_xstar
            self.eigval_J_xstar = eigval_J_xstar
            self.eigvec_J_xstar = eigvec_J_xstar
            self.has_decomposed_jacobians = eigval_J_xstar is not None

    def _alloc_nan(self, shape, dtype=None):
        '''Returns a nan-filled numpy array.

        Args:
            shape: int or tuple representing the shape of the desired numpy
            array.

        Returns:
            numpy array with the desired shape, filled with NaNs.

        '''
        if dtype is None:
            dtype = self.dtype

        result = np.zeros(shape, dtype=dtype)
        result.fill(np.nan)
        return result

    def get_unique(self):
        '''Identifies unique fixed points. Among duplicates identified,
        currently an arbitrary one is retained.

        Args:
            None.

        Returns:
            A FixedPoints object containing only the unique fixed points and
            their associated data. Uniqueness is determined down to tol_unique.
        '''

        ''' To do:
                Consider updating to leverage __contains__. This would likely
                involve slow python for loops.

                Of a set of matching fixed points (down to tol_unique), retain
                the one with the smallest qstar. Currently, an arbitrary match
                is retained.
        '''

        def unique_rows(x, approx_tol):
            # Quick and dirty. Can update using pdist if necessary
            d = int(np.round(np.max([0 -np.log10(approx_tol)])))
            ux, idx = np.unique(x.round(decimals=d),
                                axis=0,
                                return_index=True)
            return ux, idx

        if self.xstar is not None:
            if self.inputs is not None:
                data = np.concatenate((self.xstar, self.inputs), axis=1)
            else:
                data = self.xstar
        else:
            raise ValueError('Cannot find unique fixed points because '
                'self.xstar is None.')

        unique_data, idx = unique_rows(data, self.tol_unique)

        return self[idx]

    @staticmethod
    def concatenate(fps_seq):
        ''' Join a sequence of FixedPoints objects.

        Args:
            fps_seq: sequence of FixedPoints objects. All FixedPoints objects must have the following attributes in common:
                n_states
                n_inputs
                has_decomposed_jacobians

        Returns:
            A FixedPoints objects containing the concatenated FixedPoints data.
        '''

        kwargs = {}
        for attr_name in FixedPoints._data_attrs:
            if all((hasattr(fps, attr_name) for fps in fps_seq)):
                cat_list = [getattr(fps, attr_name) for fps in fps_seq]
                cat_attr = np.concatenate(cat_list, axis=0)
                kwargs[attr_name] = cat_attr

        return FixedPoints(**kwargs)

    def update(self, new_fps):
        ''' Combines the entries from another FixedPoints object into this
        object.

        All non-data class attributes remain as in this FixedPoints object
        (e.g., tol_unique, dtype, verbose).

        Args:
            new_fps: a FixedPoints object containing the entries to be
            incorporated into this FixedPoints object.

        Returns:
            None

        Raises:
            ValueError if any data attributes are found in one but not both
            FixedPoints objects (especially relevant for decomposed Jacobians).
        '''

        for attr_name in self._data_attrs:
            this_has = hasattr(self, attr_name)
            that_has = hasattr(new_fps, attr_name)
            if this_has and that_has:
                cat_attr = np.concatenate(
                    (getattr(self, attr_name),
                    getattr(new_fps, attr_name)),
                    axis=0)
                setattr(self, attr_name, cat_attr)
            elif this_has != that_has:
                raise ValueError('One but not both FixedPoints objects have %s. FixedPoints.update does not currently support this configuration.' % attr_name)

        self.n = self.n + new_fps.n

    def decompose_jacobians(self, do_batch=True, str_prefix=''):
        '''Adds the following fields to the FixedPoints object:

        eigval_J_xstar: [n x n_states] numpy array containing with
        eigval_J_xstar[i, :] containing the eigenvalues of J_xstar[i, :, :].

        eigvec_J_xstar: [n x n_states x n_states] numpy array containing with
        eigvec_J_xstar[i, :, :] containing the eigenvectors of
        J_xstar[i, :, :].
        '''

        if self.has_decomposed_jacobians:
            print('%sJacobians have already been decomposed, '
                'not repeating.' % str_prefix)
            return

        n = self.n # number of FPs represented in this object
        n_states = self.n_states # dimensionality of each state

        if do_batch:
            # Batch eigendecomposition
            print('%sDecomposing Jacobians in a single batch.' % str_prefix)

            # Check for NaNs in Jacobians
            valid_J_idx = ~np.any(np.isnan(self.J_xstar), axis=(1,2))

            if np.all(valid_J_idx):
                # No NaNs, nothing to worry about.
                e_vals_unsrt, e_vecs_unsrt = np.linalg.eig(self.J_xstar)
            else:
                # Set eigen-data to NaN if there are any NaNs in the
                # corresponding Jacobian.
                e_vals_unsrt = self._alloc_nan(
                    (n, n_states), dtype=np.complex64)
                e_vecs_unsrt = self._alloc_nan(
                    (n, n_states, n_states), dtype=np.complex64)

                e_vals_unsrt[valid_J_idx], e_vecs_unsrt[valid_J_idx] = \
                    np.linalg.eig(self.J_xstar[valid_J_idx])

        else:
            print('%sDecomposing Jacobians one-at-a-time.' % str_prefix)
            e_vals = []
            e_vecs = []
            for J in self.J_xstar:

                if np.any(np.isnan(J)):
                    e_vals_i = self._alloc_nan((n_states,))
                    e_vecs_i = self._alloc_nan((n_states, n_states))
                else:
                    e_vals_i, e_vecs_i = np.linalg.eig(J)

                e_vals.append(np.expand_dims(e_vals_i, axis=0))
                e_vecs.append(np.expand_dims(e_vecs_i, axis=0))

            e_vals_unsrt = np.concatenate(e_vals, axis=0)
            e_vecs_unsrt = np.concatenate(e_vecs, axis=0)

        print('%sSorting by Eigenvalue magnitude.' % str_prefix)
        # Sort by eigenvalue magnitude in decreasing order
        sort_idx = np.argsort(np.abs(e_vals_unsrt))[:,::-1]

        # Apply the sort
        # There must be a faster way, but I'm too lazy to find it at the moment
        self.eigval_J_xstar = \
            self._alloc_nan((n, n_states), dtype=np.complex64)
        self.eigvec_J_xstar = \
            self._alloc_nan((n, n_states, n_states), dtype=np.complex64)

        for k in range(n):
            sort_idx_k = sort_idx[k]
            self.eigval_J_xstar[k] = e_vals_unsrt[k][sort_idx_k]
            self.eigvec_J_xstar[k] = e_vecs_unsrt[k][:, sort_idx_k]

        self.has_decomposed_jacobians = True

    def __setitem__(self, index, fps):
        '''Implements the assignment opperator.

        All compatible data from fps are copied. This excludes tol_unique,
        dtype, n, n_states, and n_inputs, which retain their original values.

        Usage:
            fps_to_be_partially_overwritten[index] = fps
        '''

        if not isinstance(fps, FixedPoints):
            raise TypeError('fps must be a FixedPoints object but was %s.' %
                type(fps))

        if isinstance(index, int):
            # Force the indexing that follows to preserve numpy array ndim
            index = range(index, index+1)

        ''' Future work, test the following replacement for the rest of the
        code in this function.

        for attr_name in self._data_attrs:
            attr = getattr(self, attr_name)
            if attr is not None:
                attr[index] = getattr(fps, attr_name)
        '''

        if self.xstar is not None:
            self.xstar[index] = fps.xstar

        if self.x_init is not None:
            self.x_init[index] = fps.x_init

        if self.inputs is not None:
            self.inputs[index] = fps.inputs

        if self.F_xstar is not None:
            self.F_xstar[index] = fps.F_xstar

        if self.qstar is not None:
            self.qstar[index] = fps.qstar

        if self.dq is not None:
            self.dq[index] = fps.dq

        if self.J_xstar is not None:
            self.J_xstar[index] = fps.J_xstar

        if self.has_decomposed_jacobians:
            self.eigval_J_xstar[index] = fps.eigval_J_xstar
            self.eigvec_J_xstar[index] = fps.eigvec_J_xstar

    def __getitem__(self, index):
        '''Indexes into a subset of the fixed points and their associated data.

        Usage:
            fps_subset = fps[index]

        Args:
            index: a slice object for indexing into the FixedPoints data.

        Returns:
            A FixedPoints object containing a subset of the data from the
            current FixedPoints object, as specified by index.
        '''

        if isinstance(index, int):
            # Force the indexing that follows to preserve numpy array ndim
            index = range(index, index+1)

        xstar = self._safe_index(self.xstar, index)
        x_init = self._safe_index(self.x_init, index)
        inputs = self._safe_index(self.inputs, index)
        F_xstar = self._safe_index(self.F_xstar, index)
        qstar = self._safe_index(self.qstar, index)
        dq = self._safe_index(self.dq, index)
        n_iters = self._safe_index(self.n_iters, index)
        J_xstar = self._safe_index(self.J_xstar, index)

        if self.has_decomposed_jacobians:
            eigval_J_xstar = self._safe_index(self.eigval_J_xstar, index)
            eigvec_J_xstar = self._safe_index(self.eigvec_J_xstar, index)
        else:
            eigval_J_xstar = None
            eigvec_J_xstar = None

        dtype = self.dtype
        tol_unique = self.tol_unique

        indexed_fps = FixedPoints(xstar,
            x_init=x_init,
            inputs=inputs,
            F_xstar=F_xstar,
            qstar=qstar,
            dq=dq,
            n_iters=n_iters,
            J_xstar = J_xstar,
            eigval_J_xstar=eigval_J_xstar,
            eigvec_J_xstar=eigvec_J_xstar,
            dtype=dtype,
            tol_unique=tol_unique)

        return indexed_fps

    def __len__(self):
        '''Returns the number of fixed points stored in the object.'''
        return self.n_inits

    @staticmethod
    def _safe_index(x, idx):
        '''Safe method for indexing into a numpy array that might be None.

        Args:
            x: Either None or a numpy array.

            idx: Positive int or index-compatible argument for indexing into x.

        Returns:
            Self explanatory.

        '''
        if x is None:
            return None
        else:
            return x[idx]

    def find(self, fp):
        '''Searches in the current FixedPoints object for matches to a
        specified fixed point. Two fixed points are defined as matching
        if none of the element-wise differences between their .xstar or
        .inputs properties differ by more than tol_unique.

        Args:
            fp: A FixedPoints object containing exactly one fixed point.

        Returns:
            [n_occurrences,] numpy array specifying indices into the current
            FixedPoints object where matches to fp were found.
        '''

        # If not found or comparison is impossible (due to type or shape),
        # follow convention of np.where and return an empty numpy array.
        result = np.array([], dtype=int)

        if isinstance(fp, FixedPoints):
            if fp.n_states == self.n_states and fp.n_inputs == self.n_inputs:

                self_data = np.concatenate((self.xstar, self.inputs), axis=1)
                arg_data = np.concatenate((fp.xstar, fp.inputs), axis=1)

                elementwise_abs_diff = np.abs(self_data - arg_data)
                hits = np.all(elementwise_abs_diff <= self.tol_unique, axis=1)

                result = np.where(hits)[0]

        return result

    def __contains__(self, fp):
        '''Checks whether a specified fixed point is contained in the object.

        Args:
            xstar: [n_states,] or [1, n_states] numpy array specifying the fixed
            point of interest.

        Returns:
            bool indicating whether self.xstar contains any fixed point with a maximum elementwise difference from xstar that is less than tol_unique.
        '''
        idx = self.find(fp)

        return idx.size > 0

    def save(self, save_path):
        '''Saves all data contained in the FixedPoints object.

        Args:
            save_path: A string containing the path at which to save
            (including directory, filename, and arbitrary extension).

        Returns:
            None.
        '''
        # pass
        if self.verbose:
            print('Saving FixedPoints object.')
        file = open(save_path,'wb')
        file.write(pickle.dumps(self.__dict__))
        file.close()

    def restore(self, restore_path):
        '''Restores data from a previously saved FixedPoints object.

        Args:
            restore_path: A string containing the path at which to find a
            previously saved FixedPoints object (including directory, filename,
            and extension).

        Returns:
            None.
        '''
        if self.verbose:
            print('Restoring FixedPoints object.')
        file = open(restore_path,'rb')
        restore_data = file.read()
        file.close()
        self.__dict__ = pickle.loads(restore_data, encoding='latin1')

    def print_summary(self):
        '''Prints a summary of the fixed points.

        Args:
            None.

        Returns:
            None.
        '''

        print('\nThe q function at the fixed points:')
        print(self.qstar)

        print('\nChange in the q function from the final iteration '
              'of each optimization:')
        print(self.dq)

        print('\nNumber of iterations completed for each optimization:')
        print(self.n_iters)

        print('\nThe fixed points:')
        print(self.xstar)

        print('\nThe fixed points after one state transition:')
        print(self.F_xstar)
        print('(these should be very close to the fixed points)')

        if self.J_xstar is not None:
            print('\nThe Jacobians at the fixed points:')
            print(self.J_xstar)

    def print_shapes(self):
        ''' Prints the shapes of the data attributes of the fixed points.

        Args:
            None.

        Returns:
            None.
        '''

        for attr_name in FixedPoints._data_attrs:
            attr = getattr(self, attr_name)
            print('%s: %s' % (attr_name, str(attr.shape)))

'''Test the correctness of fixed points identified by FixedPointFinder on a
set of RNN's where ground truth fixed points have been previously identified,
numerically confirmed, and saved for comparison.
'''

N_HIDDEN_LIST = [2, 3, 4]
N_INPUTS = 1

n_tests = len(N_HIDDEN_LIST)
fpf_hps = {'do_rerun_q_outliers': True, 'verbose': False}
session = tf.Session()
TEST_PATH = os.getcwd()+'/test/ground-truth/'
did_pass_tests1 = [False] * n_tests
did_pass_tests2 = [False] * n_tests

for test_idx in range(n_tests):

    n_hidden = N_HIDDEN_LIST[test_idx]
    test_no = test_idx+1

    print('')
    print('******************************************************************')
    print('Running test %d of %d.' % (test_no, n_tests))
    print('******************************************************************')
    print('')

    ground_truth_path = get_ground_truth_path(TEST_PATH, n_hidden)
    ground_truth_fps = FixedPoints()
    ground_truth_fps.restore(ground_truth_path)
    dict_d = ground_truth_fps.__dict__
    ground_truth_fps = FixedPointStore(xstar=dict_d['xstar'],
                                        alloc_zeros = False,
                                        x_init=dict_d['x_init'],
                                        inputs=dict_d['inputs'],
                                        F_xstar = dict_d['F_xstar'],
                                        qstar = dict_d['qstar'],
                                        dq = dict_d['dq'],
                                        n_iters=dict_d['n_iters'],
                                        J_xstar=dict_d['J_xstar'],
                                        num_inits = dict_d['n'],
                                        num_states = dict_d['n_states'],
                                        num_inputs = dict_d['n_inputs'])
    # print('step1')

    # *************************************************************************
    # STEP 1: Create an RNN with prespecified parameters **********************
    # *************************************************************************
    rnn_cell = build_test_rnn(n_hidden, N_INPUTS, session)
    initial_states, inputs = generate_initial_states_and_inputs(
        n_hidden, N_INPUTS)
    # print('step2')
    # *************************************************************************
    # STEP 2: Find, analyze, and visualize the fixed points of the RNN ********
    # *************************************************************************

    # Setup the fixed point finder
    fpf = FixedPointSearch(states=None,cell=rnn_cell,ctype="Vanilla",sess=session,savepath=None)
    fpf.sampled_states = initial_states
    # Run the fixed point finder
    unique_fps, all_fps = fpf.find_fixed_points(inputs)
    #(initial_states, inputs)
    print('%d unique fixed point(s) identified.' %
          unique_fps.num_inits)
    print('%d unique fixed point(s) in ground truth set.\n' %
          ground_truth_fps.num_inits)

    # Count the number of identified fixed points that are indeed fixed points
    # (according to the ground truth set).
    n_correct = 0
    for idx_unique in range(unique_fps.num_inits):
        print(unique_fps[idx_unique])
        if unique_fps[idx_unique] in ground_truth_fps:
            n_correct += 1

    if n_correct == unique_fps.num_inits:
        print('Test %d.1: PASSED.' % test_no)
        print('\tAll identified fixed points match fixed points')
        print('\tin the ground truth set.')
        did_pass_tests1[test_idx] = True
    else:
        print('Test %d.1: FAILED.' % test_no)
        print('\t%d of %d identified fixed points do not have matches' %
              (unique_fps.num_inits - n_correct, unique_fps.num_inits))
        print('\tin the ground truth set.')

    # Count the number of ground truth fixed points that were found.
    n_gt_found = 0
    for idx_gt in range(ground_truth_fps.num_inits):
      
        if ground_truth_fps[idx_gt] in unique_fps:
            n_gt_found += 1

    if n_gt_found == ground_truth_fps.num_inits:
        print('Test %d.2: PASSED.' % test_no)
        print('\tAll ground truth fixed points match fixed points')
        print('\tin the identified set.')
        did_pass_tests2[test_idx] = True
    else:
        print('Test %d.2: FAILED.' % test_no)
        print('\t%d of %d ground truth fixed points do not have matches' %
              (ground_truth_fps.num_inits - n_gt_found, ground_truth_fps.num_inits))
        print('\tin the identified set.')

print('')
if all(did_pass_tests1) and all(did_pass_tests2):
    print('FixedPointFinder PASSED all tests.')
else:
    print('FixedPointFinder FAILED one or more tests.')
print('')


# plot_fps(unique_fps)